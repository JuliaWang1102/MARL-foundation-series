Episode 02 - References
This folder contains academic papers, research articles, and additional reading materials referenced in Episode 02. These resources provide comprehensive coverage of MARL paradigm design patterns, from centralized to decentralized approaches, along with their representative algorithms and implementations.

ðŸ“– Key Papers
CTCE (Centralized Training, Centralized Execution)
Boutilier, C. (1996). "Planning and acting in partially observable stochastic domains." TARK '96.
DOI: 10.5555/1029693.1029710

CTDE (Centralized Training, Decentralized Execution)
Sunehag, P., et al. (2017). "Value-Decomposition Networks For Cooperative Multi-Agent Learning." ArXiv preprint.
arXiv:1706.05296

Rashid, T., et al. (2018). "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning." ICML 2018.
arXiv:1803.11485

Lowe, R., et al. (2017). "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments." NeurIPS 2017.
arXiv:1706.02275

Foerster, J., et al. (2018). "Counterfactual Multi-Agent Policy Gradients." AAAI 2018.
arXiv:1705.08926

Das, A., et al. (2019). "TarMAC: Targeted Multi-Agent Communication." ICML 2019.
arXiv:1810.11187

Iqbal, S., & Sha, F. (2019). "Multi-Actor-Attention-Critic for Mixed Cooperative-Competitive Multi-Agent Reinforcement Learning." ICML 2019.
arXiv:1810.02912

Wang, T., et al. (2020). "ROMA: Multi-Agent Reinforcement Learning with Emergent Roles." ICML 2020.
arXiv:2003.08039

DTDE (Decentralized Training, Decentralized Execution)
He, H., et al. (2016). "Opponent Modeling in Deep Reinforcement Learning." ICML 2016.
arXiv:1609.05559

Hu, J., & Wellman, M. P. (2003). "Nash Q-Learning for Multi-Agent Stochastic Games." Journal of Machine Learning Research, 4, 1039-1069.
JMLR Link

Mao, W., et al. (2023). "Multi-Agent Meta-Reinforcement Learning: Sharper Convergence Rates with Task Similarity." NeurIPS 2023.
NeurIPS Link

ðŸ“š Essential Reading
Yu, C., et al. (2022). "The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games." NeurIPS 2022.
arXiv:2103.01955

Son, K., et al. (2019). "QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning." ICML 2019.
arXiv:1905.05408

Singh, A., et al. (2019). "Learning when to Communicate at Scale in Multiagent Cooperative and Competitive Tasks." ICLR 2019.
arXiv:1812.09755

ðŸ’» Implementation Resources
PyMARL Framework: The primary multi-agent reinforcement learning framework containing implementations of most algorithms discussed.
GitHub Repository

PyMARL2: Optimized version with improved performance and additional algorithms.
GitHub Repository

EPyMARL: Extended PyMARL with additional environments and algorithms.
GitHub Repository

Minimal-MARL: Educational implementations for learning MARL concepts.
GitHub Repository

ðŸ”¬ Additional Research
Tampuu, A., et al. (2017). "Multiagent cooperation and competition with deep reinforcement learning." PLoS ONE.
DOI:10.1371/journal.pone.0172395

Wang, T., et al. (2021). "Rode: Learning roles to decompose multi-agent tasks." ICLR 2021.
arXiv:2010.01523

Malucelli, N., et al. (2024). "Neighbor-Based Decentralized Training Strategies for Multi-Agent Reinforcement Learning." ACM TAAS.
DOI:10.1145/3672608.3707923
